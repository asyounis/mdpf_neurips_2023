model_files:
  - "experiments/deepmind_maze_experiments_multiple_runs/config_files/models.yaml"

models:
 
   dpf_full_training:
    type: "LSTMRnn"

    # RNN Parameters
    input_dim: 80
    output_dim: 4
    number_of_lstm_layers: 4
    internal_latent_space_dim: 256
    number_of_fc_layers: 4
    non_linear_type: "PReLU"

    # If we should use the initilizer model for initing or if we should init with the true state
    initilize_with_true_state: True
    initial_position_std: [0.5, 0.5, 0.03]


    # We want to encode the particles into a latent space
    encode_particles: True

    # The residual network output scaling factor
    residual_scale_factor: [0.99, 0.99, 0.99, 0.99]

    #  The type and number of observations to use at each time step
    observation_is_patches: False
    number_of_observation_inputs: 1

    # We need a particle transformer for the deepmind dataset
    particle_transformer: 
      transformer_type: "DeepMindTransformer"

    # The parameters for the KDE that will be used for this model
    kde:
      dims:
        0:
            distribution_type: "Normal"
        1:
            distribution_type: "Normal"
        2:
            distribution_type: "Von_Mises"


    bandwidth_model_fixed:
      type: "FixedBandwith"
      starting_bandwidths: [2.0, 2.0, 0.5]
      min_bandwidths: [0.1, 0.1, 0.001]

save_dir_root: experiments/deepmind_maze_experiments_multiple_runs/lstm_rnn/saves/


experiments_import:
  - "experiments/deepmind_maze_experiments_multiple_runs/config_files/generated/lstm_experiments.yaml"





# experiments_local_override:
#   - full_dpf_full_training_maze_1_mse_000:
#       do_run: false

#   - full_dpf_full_training_maze_1_mse_001:
#       do_run: false

#   - full_dpf_full_training_maze_1_mse_002:
#       do_run: false

#   - full_dpf_full_training_maze_1_mse_003:
#       do_run: false

#   - full_dpf_full_training_maze_1_mse_004:
#       do_run: false

#   - full_dpf_full_training_maze_1_000:
#       do_run: false

#   - full_dpf_full_training_maze_1_001:
#       do_run: false

#   - full_dpf_full_training_maze_1_002:
#       do_run: false

#   - full_dpf_full_training_maze_1_003:
#       do_run: false

#   - full_dpf_full_training_maze_1_004:
#       do_run: false








#   - full_dpf_full_training_maze_2_mse_000:
#       do_run: False

#   - full_dpf_full_training_maze_2_mse_001:
#       do_run: False

#   - full_dpf_full_training_maze_2_mse_002:
#       do_run: False

#   - full_dpf_full_training_maze_2_mse_003:
#       do_run: False

#   - full_dpf_full_training_maze_2_mse_004:
#       do_run: False

#   - full_dpf_full_training_maze_2_000:
#       do_run: False

#   - full_dpf_full_training_maze_2_001:
#       do_run: False

#   - full_dpf_full_training_maze_2_002:
#       do_run: False

#   - full_dpf_full_training_maze_2_003:
#       do_run: False

#   - full_dpf_full_training_maze_2_004:
#       do_run: False




#   - full_dpf_full_training_maze_3_mse_000:
#       do_run: False

#   - full_dpf_full_training_maze_3_mse_001:
#       do_run: False

#   - full_dpf_full_training_maze_3_mse_002:
#       do_run: False

#   - full_dpf_full_training_maze_3_mse_003:
#       do_run: False

#   - full_dpf_full_training_maze_3_mse_004:
#       do_run: False

#   - full_dpf_full_training_maze_3_000:
#       do_run: False

#   - full_dpf_full_training_maze_3_001:
#       do_run: False

#   - full_dpf_full_training_maze_3_002:
#       do_run: False

#   - full_dpf_full_training_maze_3_003:
#       do_run: False

#   - full_dpf_full_training_maze_3_004:
#       do_run: False
